{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":14,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This tutorial was created based on: https://scikit-learn.org/stable/auto_examples/compose/plot_digits_pipe.html#sphx-glr-auto-examples-compose-plot-digits-pipe-py"},{"metadata":{"trusted":true},"cell_type":"code","source":"# First of all, import the dataset\nfrom sklearn import datasets\n\nX_digits, y_digits = datasets.load_digits(return_X_y=True)\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_digits, y_digits, test_size=0.33, random_state=42)\n\nprint(X_digits.shape)","execution_count":20,"outputs":[{"output_type":"stream","text":"(1797, 64)\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# We want to process the dataset in two steps, containing a PCA truncation and a classifier regularization\n# input ---> PCA ---> LogisticRegression ---> output \n\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression\n","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Naive way to do this:\n# Seems simple in the beginning, becomes quite messy after some transformations\n# So please, don't do this when there is a better way\n\n# First, transform the input using PCA\npca = PCA(n_components=2)\npca.fit(X_train)\nX_train_pca = pca.transform(X_train)\n\n# Then, fit a logistic regression for the transformed X and y\nlogistic = LogisticRegression(max_iter=10000, tol=0.1) # note: max_iter is low, tolerance is high: just to make the example faster\nlogistic.fit(X_train_pca, y_train)\n\n# Make a prediction and evaluate the model on the training set\ny_train_pred = logistic.predict(X_train_pca)\n\n# To predict for the test set, we need to transform the X_test first\nX_test_pca = pca.transform(X_test) # note: we must not fit for pca for X_test!\n\n# Then, we have to use the regression for prediction and evaluate on the test set (again: no fit for X_test!)\ny_test_pred = logistic.predict(X_test_pca)\n\n# Well, not that complicated. But try doing a grid search seeking the best parameter combinations for PCA and LogisticRegression.\n# Even better, chain togethet multiple steps and do the same...\n# We would like to handle chaining the processing steps together, so that we have one big fit() and predict() function sending the data through all of them\n","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Smart solution: pipelines\n# Lets define a pipeline, chaining the steps together, so this:\n# input ---> PCA ---> LogisticRegression ---> output\n# can become this:\n# input ---> Pipeline ---> output\n# where pipeline executes the above steps\n\nfrom sklearn.pipeline import Pipeline\n\npca = PCA(n_components=2)\nlogistic = LogisticRegression(max_iter=10000, tol=0.1)\n\npipe = Pipeline(steps=[('pca', pca), ('logistic', logistic)]) # all steps must have a name and an object doing that step\npipe.fit(X_train, y_train)\n\ny_train_pred = pipe.predict(X_train)\ny_test_pred = pipe.predict(X_test)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Grid search using pipelines\nfrom sklearn.model_selection import GridSearchCV\n\n# Define the pipeline\npca = PCA()\nlogistic = LogisticRegression(max_iter=10000, tol=0.1)\npipe = Pipeline(steps=[('pca', pca), ('logistic', logistic)])\n\n# Parameters of pipelines can be set using ‘__’ separated parameter names:\nparam_grid = {\n    'pca__n_components': [5, 15, 30, 45, 64],\n    'logistic__C': np.logspace(-4, 4, 4),\n}\n\nsearch = GridSearchCV(pipe, param_grid, n_jobs=-1)\nsearch.fit(X_digits, y_digits)\n\nprint(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\nprint(search.best_params_)","execution_count":19,"outputs":[{"output_type":"stream","text":"Best parameter (CV score=0.920):\n{'logistic__C': 0.046415888336127774, 'pca__n_components': 45}\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the PCA spectrum\npca.fit(X_digits)\n\nfig, (ax0, ax1) = plt.subplots(nrows=2, sharex=True, figsize=(6, 6))\nax0.plot(np.arange(1, pca.n_components_ + 1),\n         pca.explained_variance_ratio_, '+', linewidth=2)\nax0.set_ylabel('PCA explained variance ratio')\n\nax0.axvline(search.best_estimator_.named_steps['pca'].n_components,\n            linestyle=':', label='n_components chosen')\nax0.legend(prop=dict(size=12))\n\n# For each number of components, find the best classifier results\nresults = pd.DataFrame(search.cv_results_)\ncomponents_col = 'param_pca__n_components'\nbest_clfs = results.groupby(components_col).apply(\n    lambda g: g.nlargest(1, 'mean_test_score'))\n\nbest_clfs.plot(x=components_col, y='mean_test_score', yerr='std_test_score',\n               legend=False, ax=ax1)\nax1.set_ylabel('Classification accuracy (val)')\nax1.set_xlabel('n_components')\n\nplt.xlim(-1, 70)\n\nplt.tight_layout()\nplt.show()","execution_count":21,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'plt' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-4e8b5d5d6e92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_digits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m ax0.plot(np.arange(1, pca.n_components_ + 1),\n\u001b[1;32m      6\u001b[0m          pca.explained_variance_ratio_, '+', linewidth=2)\n","\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"]}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}